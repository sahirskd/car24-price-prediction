# -*- coding: utf-8 -*-
"""Car-price-prediction_practice-2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uCmPjeH0B6uiTnCb1l-ARqGIJWmgM8sQ
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from statsmodels.stats.outliers_influence import variance_inflation_factor

!gdown 1qXoDeYVC4vhd7xTNwohxh9dMCjjtoHoJ

df = pd.read_csv("cars24-car-price-cleaned-new.csv")
df

df_train, df_test = train_test_split(df, test_size=0.2, random_state=32)

df_train

df_test

df['make'].nunique()

pd.get_dummies(df["make"], drop_first=True)

df_train.groupby('make')['selling_price'].agg('mean').sort_values(ascending=False)

model_wise_mean = df_train.groupby('model')['selling_price'].mean()
make_wise_mean = df_train.groupby('make')['selling_price'].mean()

make_wise_mean

df_train['make'] = df_train.groupby('make')['selling_price'].transform('mean')
df_train['model'] = df_train.groupby('model')['selling_price'].transform('mean')
df_train

df_test['make'] = df_test['make'].map(make_wise_mean)
df_test['model'] = df_test['model'].map(model_wise_mean)
df_test

df_train.isna().sum()

df_test.isna().sum()

global_mean = df_train['selling_price'].mean()
global_mean

df_test['make'] = df_test['make'].fillna(global_mean)
df_test['model'] = df_test['model'].fillna(global_mean)

scaler = MinMaxScaler()

# df_train

scaler.fit(df_train)

df_train = pd.DataFrame(scaler.fit_transform(df_train), columns=df.columns)
df_test = pd.DataFrame(scaler.transform(df_test), columns=df.columns)
# df.columns

display(df_train)
display(df_test)

y_train = df_train['selling_price']
x_train = df_train.drop('selling_price', axis=1)
y_test = df_test['selling_price']
x_test = df_test.drop('selling_price', axis=1)
display(x_train.head())
# display(y_test.head())

model = LinearRegression()
model.fit(x_train, y_train)

model.coef_

model.intercept_

model.score(x_train, y_train)
# train score

model.score(x_test, y_test)
# test score

"""## Assumptions"""

y_pred_train = model.predict(x_train)
residual_train = y_train - y_pred_train
residual_train

plt.hist(residual_train, bins=50)
plt.show()

feature_importance = pd.Series(abs(model.coef_), index=x_train.columns).sort_values(ascending=False)

feature_importance

# importance of columns
plt.figure(figsize=(10, 6))
feature_importance.plot(kind='bar')
plt.xlabel('Feature Names')
plt.ylabel('Absolute Coefficient Value')
plt.title("Feature Importance")
plt.show()

x_train.values

plt.figure(figsize=(10,6))
sns.scatterplot(data=df, x='mileage', y='selling_price')

# Calculating VIF for all features
vif_df = pd.DataFrame()
vif_df['features'] = x_train.columns
vif_df['VIF'] = [variance_inflation_factor(x_train.values, i) for i in range(x_train.shape[1])]
vif_df.sort_values(by='VIF', ascending=False, inplace=True)

highest_vif = vif_df.iloc[0]['features']
print(f'feature to remove: {highest_vif}')
x_train.drop(highest_vif, axis=1, inplace=True)
x_test.drop(highest_vif, axis=1, inplace=True)

# Calculating VIF for all features
vif_df = pd.DataFrame()
vif_df['features'] = x_train.columns
vif_df['VIF'] = [variance_inflation_factor(x_train.values, i) for i in range(x_train.shape[1])]
vif_df.sort_values(by='VIF', ascending=False, inplace=True)
vif_df

x_train
x_test

model1 = LinearRegression()

model1.fit(x_train, y_train)

train_score = model1.score(x_train, y_train)
test_score = model1.score(x_test, y_test)

y_pred_train1 = model1.predict(x_train)

print(f'Train R Score: {train_score}')
print(f'Test R Score: {test_score}')

"""Above model is overfitting"""

plt.figure(figsize=(10,6))
plt.scatter(y_pred_train, residual_train, alpha=0.5)
plt.title("Residual vs Predicted values train")
plt.xlabel('Predicted values')
plt.ylabel('Residual Values')
plt.axhline(y=0, color='r', linestyle='--')
plt.grid(True)
plt.show()

"""### Observations:

*   Residuals are not randomly scattered
*   There is a visible triangular pattern, meaning the error changes as the predicted values are increasing
*   Some points from a sloped pattern near the right side, suggesting systematic prediction error.
*   Some residuals are far from zero are possible outliers

---


### **ðŸ“Œ Inference**

* The model **violates the homoscedasticity assumption** because the variance of residuals increases with predicted values.
* The pattern suggests that the model is **not capturing some relationship in the data** â€” possibly **non-linearity or missing features**.
* The right-side diagonal pattern indicates the model may be **overfitting or saturating**, meaning it consistently under- or over-predicts for certain ranges.
* A better model (Polynomial Regression, Tree-based models, or feature engineering) may improve performance.
"""

plt.figure(figsize=(10,6))
plt.scatter(y_train, residual_train, alpha=0.5)
plt.title('Actual Y vs Residuals')
plt.xlabel('Actual Y values')
plt.ylabel('Residuals')
plt.grid(True)
plt.axhline(y=0, color='r', linestyle='--')
plt.show()

# Applying Polynomial Regression

from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import Ridge, Lasso
from sklearn.feature_selection import RFE
from sklearn.pipeline import Pipeline

degrees = [1,2,3]
train_r2 = []
test_r2 = []

for degree in degrees:
  model_pipeline = make_pipeline(
    PolynomialFeatures(degree=degree),
    LinearRegression()
  )
  model_pipeline.fit(x_train, y_train)

  print(f'Train:- Degree: {degree} R2: {model_pipeline.score(x_train, y_train)}')
  print(f'Test:- Degree: {degree} R2: {model_pipeline.score(x_test, y_test)}')

  train_r2.append(model_pipeline.score(x_train, y_train))
  test_r2.append(model_pipeline.score(x_test, y_test))

plt.figure(figsize=(10,6))
plt.plot(degrees, train_r2, marker='o', label='Train r2')
plt.plot(degrees, test_r2, marker='o', label='Test r2')
plt.title('Train vs Test r2 for different polynomial degrees')
plt.xlabel('Polynomical Degrees')
plt.ylabel('R2 Values')
plt.grid(True)
plt.legend()
plt.show()

# RFE implementation
estimator = LinearRegression()

num_of_features_to_select = x_train.shape[1]//2
print(num_of_features_to_select)
rfe_selector = RFE(estimator=estimator, n_features_to_select=num_of_features_to_select)

rfe_selector.fit(x_train, y_train)

print(rfe_selector.support_)
print(rfe_selector.ranking_)

selected_columns_rfe = x_train.columns[rfe_selector.support_]
feature_ranking_rfe = pd.Series(rfe_selector.ranking_, index=x_train.columns)
print('Selected Features Array: ')
display(selected_columns_rfe)
display(feature_ranking_rfe.sort_values())

x_train_rfe = x_train[selected_columns_rfe]
x_test_rfe = x_test[selected_columns_rfe]

display(x_train_rfe)

# Applying polynomial features on rfe selected features
poly = PolynomialFeatures(degree = 3)

x_train_poly = poly.fit_transform(x_train_rfe)
x_test_poly = poly.transform(x_test_rfe)

# display(x_train_poly[4])

# Define a list of alpha values to evaluate (same as Lasso for comparison)
alphas = [0.001, 0.01, 0.1, 1, 10]

print("Lasso & Ridge Regression with Polynomial Features:")
print("="*60)
for alpha in alphas:
    ridge_model = Ridge(alpha=alpha)
    ridge_model.fit(x_train_poly, y_train)
    train_r2_ridge = ridge_model.score(x_train_poly, y_train)
    test_r2_ridge = ridge_model.score(x_test_poly, y_test)

    lasso_model = Lasso(alpha=alpha)
    lasso_model.fit(x_train_poly, y_train)
    train_r2_lasso = lasso_model.score(x_train_poly, y_train)
    test_r2_lasso = lasso_model.score(x_test_poly, y_test)

    print(f"Alpha: {alpha}")
    print(f"Ridge: Train R-2: {train_r2_ridge:.4f}, Test R-2: {test_r2_ridge:.4f}")
    print(f"Lasso: Train R-2: {train_r2_lasso:.4f}, Test R-2: {test_r2_lasso:.4f}")

"""### Now we can observe from above data:

Ridge: Alpha: 0.001, Train R-2: 0.9566, Test R-2: 0.8779: This Iteration is giving best result and alpha value is **0.001**

"""

# Final Model with complete pipeline

BEST_POLY_DEGREE = 4
BEST_ALPHA = 0.01

final_pipeline = Pipeline([
    ('scaler', MinMaxScaler()),
    ('polynomial', PolynomialFeatures(degree=BEST_POLY_DEGREE)),
    ('model', Ridge(alpha=BEST_ALPHA)),
])

final_pipeline.fit(x_train_rfe, y_train)

r2_train_pipeline = final_pipeline.score(x_train_rfe, y_train)
r2_test_pipeline = final_pipeline.score(x_test_rfe, y_test)

print(f'Pipeline: Train r2: {r2_train_pipeline}, Test: {r2_test_pipeline}')

final_y_pred = final_pipeline.predict(x_test_rfe)
final_residuals = y_test - final_y_pred



plt.figure(figsize=(10,6))
plt.scatter(final_y_pred, final_residuals, alpha=0.5)
plt.title("Residual vs Predicted values train")
plt.xlabel('Predicted values')
plt.ylabel('Residual Values')
plt.axhline(y=0, color='r', linestyle='--')
plt.grid(True)
plt.show()